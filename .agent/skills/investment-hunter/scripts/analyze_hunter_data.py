import pandas as pd
import os
import argparse
from datetime import datetime

def analyze_hunter_data(data_dir):
    """
    æ ¹æ® Investment Hunter ç­–ç•¥åˆ†ææŒ‡å®šç›®å½•ä¸‹çš„æœ€æ–°é‡‘èæ•°æ®ã€‚
    """
    if not os.path.exists(data_dir):
        print(f"Error: ç›®å½• {data_dir} ä¸å­˜åœ¨ã€‚")
        return

    # QQQ
    qqq_path = os.path.join(data_dir, 'QQQ_MA20.csv')
    if not os.path.exists(qqq_path):
         print(f"Error: {qqq_path} ä¸å­˜åœ¨ã€‚")
         return
         
    qqq = pd.read_csv(qqq_path)
    latest_qqq = qqq.iloc[-1]
    close = latest_qqq['Close']
    ma20 = latest_qqq['MA20']
    gap = (close - ma20) / (ma20 + 1e-9) * 100
    rolling_max = qqq['Close'].max()
    drawdown = (close - rolling_max) / (rolling_max + 1e-9) * 100

    # DGS2 (Rate Shock)
    dgs2_path = os.path.join(data_dir, 'DGS2.csv')
    if not os.path.exists(dgs2_path):
        print(f"Error: {dgs2_path} ä¸å­˜åœ¨ã€‚")
        return
        
    dgs2 = pd.read_csv(dgs2_path)
    dgs2['Date'] = pd.to_datetime(dgs2['Date'])
    dgs2 = dgs2.sort_values('Date').dropna()
    latest_dgs2 = dgs2.iloc[-1]['Value']
    
    if len(dgs2) > 40:
        dgs2_40 = dgs2.iloc[-41]['Value']
    else:
        dgs2_40 = dgs2.iloc[0]['Value']
        
    rate_mom = (latest_dgs2 - dgs2_40) / (dgs2_40 + 1e-9) * 100

    def get_macro(filename):
        try:
            df = pd.read_csv(os.path.join(data_dir, filename))
            if 'Value' not in df.columns:
                return 0, 'â€”'
            df['Date'] = pd.to_datetime(df['Date'])
            df['Value'] = pd.to_numeric(df['Value'], errors='coerce')
            df = df.sort_values('Date').dropna()
            
            if len(df) == 0:
                return 0, 'â€”'
                
            latest = df.iloc[-1]['Value']
            prev = df.iloc[-2]['Value'] if len(df) > 1 else latest
            trend = 'â¬†ï¸' if latest > prev else 'â¬‡ï¸' if latest < prev else 'â€”'
            return latest, trend
        except Exception as e:
            return 0, 'â€”'

    wresbal_val, wresbal_trend = get_macro('WRESBAL.csv')
    wtregen_val, wtregen_trend = get_macro('WTREGEN.csv')
    rrp_val, rrp_trend = get_macro('RRPONTSYD.csv')
    hy_val, hy_trend = get_macro('BAMLH0A0HYM2.csv')
    
    try:
        move_val, move_trend = get_macro('MOVE.csv')
    except:
        move_val, move_trend = 0, 'â€”'
        
    dxy_val, dxy_trend = get_macro('DTWEXBGS.csv')
    wti_val, wti_trend = get_macro('DCOILWTICO.csv')
    copper_gold_val, copper_gold_trend = get_macro('COPPER_GOLD_RATIO.csv')

    print("==================================================")
    print("ğŸ¯ INVESTMENT HUNTER æ•°æ®æå–")
    print("==================================================")
    print(f"\n[1] æ ¸å¿ƒä¿¡å·æ•°æ®:")
    print(f"  QQQ æ”¶ç›˜ä»·       : ${close:.2f}")
    print(f"  QQQ 20æ—¥å‡çº¿     : ${ma20:.2f}")
    print(f"  è·å‡çº¿è·ç¦» (Gap) : {gap:+.2f}%")
    print(f"  å†å²æœ€é«˜ä»·       : ${rolling_max:.2f}")
    print(f"  æœ€å¤§å›æ’¤ (DD)    : {drawdown:.2f}% (å¦‚æœ< -15% è§¦å‘ KRAKEN)")
    print(f"  2å¹´æœŸç¾å€º (DGS2) : {latest_dgs2:.4f}")
    print(f"  40æ—¥å‰DGS2       : {dgs2_40:.4f}")
    print(f"  Rate Momentum    : {rate_mom:+.2f}% (å¦‚æœ> 20% è§¦å‘ RATE_SHOCK)")
    
    print(f"\n[2] å®è§‚è¿‡æ»¤å™¨:")
    print(f"  é“¶è¡Œå‡†å¤‡é‡‘(WRESBAL) : {wresbal_val:,.2f} M {wresbal_trend}")
    print(f"  TGAè´¦æˆ·(WTREGEN)    : {wtregen_val:,.2f} M {wtregen_trend}")
    print(f"  é€†å›è´­(RRPONTSYD)   : {rrp_val:.2f} B {rrp_trend}")
    print(f"  é«˜æ”¶ç›Šå€ºåˆ©å·®(HY)    : {hy_val:.2f}% {hy_trend}")
    print(f"  MOVEæŒ‡æ•°            : {move_val:.2f} {move_trend}")
    print(f"  ç¾å…ƒæŒ‡æ•°(DXY)       : {dxy_val:.2f} {dxy_trend}")
    print(f"  WTIåŸæ²¹             : ${wti_val:.2f} {wti_trend}")
    print(f"  é“œé‡‘æ¯”              : {copper_gold_val:.6f} {copper_gold_trend}")
    print("==================================================")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='åˆ†æ Investment Hunter éœ€è¦çš„å¸‚åœºæ•°æ®')
    parser.add_argument('--date', type=str, help='æŒ‡å®šæ•°æ®æ—¥æœŸæ–‡ä»¶å¤¹åç§°ï¼Œå¦‚ "2023-10-25"ã€‚å¦‚æœä¸æŒ‡å®šï¼Œå°†ä½¿ç”¨ datas/analysis ä¸‹æœ€æ–°çš„æ—¥æœŸæ–‡ä»¶å¤¹ã€‚')
    args = parser.parse_args()

    base_dir = '/Users/patrick_0000/develop/AIPOC/FinanceAgent/datas/analysis'
    
    target_dir = None
    if args.date:
        target_dir = os.path.join(base_dir, args.date)
    else:
        # å¯»æ‰¾æœ€æ–°çš„ç›®å½•
        try:
             # è·å–æ‰€æœ‰æ˜¯ç›®å½•çš„é¡¹ï¼Œå¹¶æ’é™¤å¯èƒ½å­˜åœ¨çš„éæ—¥æœŸæ ¼å¼ç›®å½•
             dirs = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]
             # åªä¿ç•™ç¬¦åˆæ—¥æœŸæ ¼å¼(ç®€æ˜“åˆ¤æ–­)çš„æ–‡ä»¶å¤¹å¹¶æ’åº
             date_dirs = sorted([d for d in dirs if len(d) == 10 and d.count('-') == 2])
             if date_dirs:
                 target_dir = os.path.join(base_dir, date_dirs[-1])
        except Exception as e:
             pass

    if target_dir:
        print(f"è¯»å–æ•°æ®ç›®å½•: {target_dir}")
        analyze_hunter_data(target_dir)
    else:
         print(f"Error: æ— æ³•åœ¨ {base_dir} ä¸‹æ‰¾åˆ°æœ‰æ•ˆçš„æ—¥æœŸæ•°æ®ç›®å½•ã€‚")
